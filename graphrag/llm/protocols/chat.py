# Copyright (c) 2025 Microsoft Corporation.
# Licensed under the MIT License

from __future__ import annotations
from typing import Protocol, List, Any

class ChatLLM(Protocol):
    def chat(self, prompt: str, **kwargs: Any) -> str:
        """
        Generate a chat response based on the provided prompt.

        Args:
            prompt: The text prompt to generate a response for.
            **kwargs: Additional keyword arguments (e.g., temperature, max_tokens).

        Returns:
            A string response generated by the LLM.
        """
        ...